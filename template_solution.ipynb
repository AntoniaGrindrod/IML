{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General guidance\n",
    "\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised\n",
    "to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`.\n",
    "\n",
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Add any additional imports here (however, the task is solvable without using \n",
    "# any additional imports)\n",
    "# import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1   x2     x3   x4     x5     x6     x7      x8    x9    x10   x11  \\\n",
      "0   0.06724  0.0   3.24  0.0  0.460  6.333   17.2  5.2146   4.0  430.0  16.9   \n",
      "1   9.23230  0.0  18.10  0.0  0.631  6.216  100.0  1.1691  24.0  666.0  20.2   \n",
      "2   0.11425  0.0  13.89  1.0  0.550  6.373   92.4  3.3633   5.0  276.0  16.4   \n",
      "3  24.80170  0.0  18.10  0.0  0.693  5.349   96.0  1.7028  24.0  666.0  20.2   \n",
      "4   0.05646  0.0  12.83  0.0  0.437  6.232   53.7  5.0141   5.0  398.0  18.7   \n",
      "\n",
      "      x12    x13  \n",
      "0  375.21   7.34  \n",
      "1  366.15   9.53  \n",
      "2  393.74  10.50  \n",
      "3  396.90  19.77  \n",
      "4  386.40  12.34  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "y = data[\"y\"].to_numpy()\n",
    "data = data.drop(columns=\"y\")\n",
    "# print a few data samples\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the average RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(w, X, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of \n",
    "    predicting y from X using a linear model with weights w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression \n",
    "    X: matrix of floats, dim = (15,13), inputs with 13 features\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "    RMSE = 0\n",
    "\n",
    "    #Use formula RMSE = sqrt(1/n*sum_{i=1}^{n} (y_i-\\hat{y}_i)^2)\n",
    "    RMSE=np.sqrt(sum((y - X@w)**2)/len(y))\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, lam):\n",
    "    \"\"\"\n",
    "    This function receives training data points, then fits the ridge regression on this data\n",
    "    with regularization hyperparameter lambda. The weights w of the fitted ridge regression\n",
    "    are returned. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (135,13), inputs with 13 features\n",
    "    y: array of floats, dim = (135,), input labels)\n",
    "    lam: float. lambda parameter, used in regularization term\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression\n",
    "    \"\"\"\n",
    "    #Use formula \\hat{w} = (((X^T)X +lam*I)^(-1))(X^T)y\n",
    "    w= np.linalg.inv(np.transpose(X)@X+lam*np.identity(len(X[0])))@np.transpose(X)@y\n",
    "    #use of np.transpose() function (and many of the other functions used) assumes X is given as numpy array. \n",
    "    #So might have to convert X into numpy array if it's not given as one.\n",
    "    assert w.shape == (13,)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_RMSE(X, lambdas, n_folds): #we dont use the parameter y as defined below? \n",
    "    \"\"\"\n",
    "    Main cross-validation loop, implementing 10-fold CV. In every iteration \n",
    "    (for every train-test split), the RMSE for every lambda is calculated, \n",
    "    and then averaged over iterations.\n",
    "\n",
    "    Parameters\n",
    "    ---------- \n",
    "    X: matrix of floats, dim = (150, 13), inputs with 13 features\n",
    "    y: array of floats, dim = (150, ), input labels\n",
    "    lambdas: list of floats, len = 5, values of lambda for which ridge regression is fitted and RMSE estimated\n",
    "    n_folds: int, number of folds (pieces in which we split the dataset), parameter K in KFold CV\n",
    "\n",
    "    Compute\n",
    "    ----------\n",
    "    avg_RMSE: array of floats: dim = (5,), average RMSE value for every lambda\n",
    "    \"\"\"\n",
    "    # The function calculating the average RMSE\n",
    "\n",
    "    RMSE_mat = np.zeros((n_folds, len(lambdas)))\n",
    "\n",
    "    # TODO: Enter your code here. Hint: Use functions 'fit' and 'calculate_RMSE' with training and test data\n",
    "    # and fill all entries in the matrix 'RMSE_mat'\n",
    "\n",
    "    kf = KFold(n_splits=n_folds) \n",
    "\n",
    "    for fold_index, (train, test) in enumerate(kf.split(X)): #section 3.1.2.1 from scikit guide \n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "        for lam_index, lam in enumerate(lambdas):\n",
    "            w = fit(X_train, y_train, lam) #computing weigths using function 'fit'\n",
    "            RMSE_mat[fold_index][lam_index] = calculate_RMSE(w, X_test, y_test)\n",
    "\n",
    "        avg_RMSE = np.mean(RMSE_mat, axis=0) # avg_RMSE: array of floats: dim = (5,), average RMSE value for every lambda\n",
    "\n",
    "    assert avg_RMSE.shape == (5,)\n",
    "    return avg_RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.to_numpy() #matrix of floats, dim = (150, 13), inputs with 13 features as defined in avg_RMSE function \n",
    "lambdas = [0.1, 1, 10, 100, 200]\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in the required format\n",
    "np.savetxt(\"./results.csv\", avg_RMSE(X, lambdas, n_folds), fmt=\"%.12f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ml",
   "language": "python",
   "name": "intro-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
